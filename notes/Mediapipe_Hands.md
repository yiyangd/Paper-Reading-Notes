Here's the combined English paragraph:

We present a **real-time, on-device hand tracking solution** that **predicts a human hand skeleton from a single RGB camera** for AR/VR applications. Our pipeline consists two models: 1) a palm detector that provides a bounding box of a hand and a hand landmark model that predicts the hand skeleton. This solution is implemented using MediaPipe, a framework for building cross-platform ML solutions. The proposed model and pipeline architecture exhibit real-time inference speed on mobile GPUs with high prediction quality. MediaPipe Hands is open-sourced at https://mediapipe.dev.

And here's the Chinese translation:

我们提供了一个**实时的、部署在设备上的手部追踪解决方案**，该方案**从单个RGB摄像头预测人的手骨架**，用于AR/VR应用。我们的流程包括两个模型：一个掌部检测器，它提供手的边界框；和一个手部标记模型，它预测手的骨架。这个解决方案是使用MediaPipe实现的，这是一个用于构建跨平台ML解决方案的框架。所提出的模型和流程架构在移动GPU上展示了实时推理速度，具有高预测质量。MediaPipe Hands在https://mediapipe.dev上开源。
